{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T22:30:35.995747Z",
     "start_time": "2025-11-09T22:26:22.471464Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json, re, unicodedata\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_URL = \"https://smarthome.uni-regensburg.de/naehrwertrechner/api/1.0/recipe_info_optifast\"\n",
    "\n",
    "\n",
    "def call_api(prompt: str) -> Optional[Dict[str, Any]]:\n",
    "    payload = {\"recipe\": prompt}\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers, verify=False, timeout=15)\n",
    "        return response.json() if response.ok else None\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    \"\"\"Keep German letters (äöüß), normalize/clean for stable substring match.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFC\", s).lower()\n",
    "    s = \"\".join(ch if (ch.isalnum() or ch.isspace()) else \" \" for ch in s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def parse_detail(res: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Expect:\n",
    "      {\"detailed_info\":[[\n",
    "          {\"bezeichnung\":\"...\", \"einheit\":\"g|stück|liter\", \"menge\":\"...\"},\n",
    "          {\"ZF\":..., \"ZE\":..., \"ZK\":..., \"GCAL\":..., \"ZA\":...}\n",
    "      ]]}\n",
    "    Returns (recognized_name, nutrients_dict) or (\"\", {}).\n",
    "    \"\"\"\n",
    "    di = res.get(\"detailed_info\")\n",
    "    if not isinstance(di, list) or not di:\n",
    "        return \"\", {}\n",
    "    row = di[0]\n",
    "    if not isinstance(row, list) or len(row) < 2:\n",
    "        return \"\", {}\n",
    "    meta, nutr = row[0], row[1]\n",
    "    name = meta.get(\"bezeichnung\") if isinstance(meta, dict) else \"\"\n",
    "    if not isinstance(nutr, dict):\n",
    "        nutr = {}\n",
    "    return str(name or \"\"), nutr\n",
    "\n",
    "def is_unrecognized(res: Optional[Dict[str, Any]]) -> bool:\n",
    "    if not isinstance(res, dict):\n",
    "        return True\n",
    "    name, _ = parse_detail(res)\n",
    "    return (not name) or norm(name).startswith(\"nicht erkannt\")\n",
    "\n",
    "def _strip_diacritics(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFD\", s)\n",
    "    return \"\".join(ch for ch in s if unicodedata.category(ch) != \"Mn\")\n",
    "\n",
    "def _de_ascii_fallback(s: str) -> str:\n",
    "    return (\n",
    "        s.replace(\"ä\", \"ae\")\n",
    "         .replace(\"ö\", \"oe\")\n",
    "         .replace(\"ü\", \"ue\")\n",
    "         .replace(\"ß\", \"ss\")\n",
    "    )\n",
    "GER_STOP = {\n",
    "    \"aus\",\"der\",\"die\",\"das\",\"den\",\"dem\",\"des\",\"von\",\"mit\",\"und\",\"oder\",\"ohne\",\n",
    "    \"ein\",\"eine\",\"einer\",\"einem\",\"einen\",\n",
    "    \"g\",\"gramm\",\"kg\",\"ml\",\"l\",\"liter\",\"stück\",\"stueck\",\"stk\",\n",
    "    \"grün\",\"gruen\",\"rot\",\"gelb\",\"weiß\",\"weiss\",\"hell\",\"dunkel\",\"klein\",\"groß\",\"gross\",\"mittel\",\n",
    "}\n",
    "\n",
    "def _soft_regex_match(ingredient: str, recognized_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    True if all tokens from recognized_name (minus stopwords) occur somewhere\n",
    "    in ingredient, in any order. Allows simple plural/suffix variants.\n",
    "    \"\"\"\n",
    "    a = norm(ingredient)\n",
    "    b = norm(recognized_name)\n",
    "    tokens = [t for t in b.split() if t and t not in GER_STOP]\n",
    "    if not tokens:\n",
    "        return False\n",
    "    # positive lookaheads for each token; allow common German endings\n",
    "    lookaheads = [\n",
    "        rf\"(?=.*\\b{re.escape(t)}(?:e|en|er|n|s)?\\b)\"\n",
    "        for t in tokens\n",
    "    ]\n",
    "    pattern = rf\"^{''.join(lookaheads)}.*$\"\n",
    "    return re.search(pattern, a) is not None\n",
    "\n",
    "def ingredient_matches(ingredient: str, recognized_name: str) -> bool:\n",
    "    a, b = norm(ingredient), norm(recognized_name)\n",
    "    if not a or not b:\n",
    "        return False\n",
    "\n",
    "    # 1) current quick passes\n",
    "    if a in b or b in a: return True\n",
    "    if a.replace(\" \", \"\") in b.replace(\" \", \"\") or b.replace(\" \", \"\") in a.replace(\" \", \"\"): return True\n",
    "\n",
    "    # 2) diacritic / ASCII fallbacks you already have...\n",
    "    a1, b1 = _strip_diacritics(a), _strip_diacritics(b)\n",
    "    if a1 in b1 or b1 in a1: return True\n",
    "    if a1.replace(\" \", \"\") in b1.replace(\" \", \"\") or b1.replace(\" \", \"\") in a1.replace(\" \", \"\"): return True\n",
    "    a2, b2 = _de_ascii_fallback(a), _de_ascii_fallback(b)\n",
    "    if a2 in b2 or b2 in a2: return True\n",
    "    if a2.replace(\" \", \"\") in b2.replace(\" \", \"\") or b2.replace(\" \", \"\") in a2.replace(\" \", \"\"): return True\n",
    "\n",
    "    # 3) regex fallback (order-free, non-contiguous)\n",
    "    if _soft_regex_match(ingredient, recognized_name):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "WATER_TOKENS = {\"wasser\", \"mineralwasser\", \"leitungswasser\", \"sprudelwasser\", \"tafelwasser\"}\n",
    "\n",
    "def _extract_gcal(res: Dict[str, Any]) -> Optional[float]:\n",
    "    _, nutr = parse_detail(res)\n",
    "    try:\n",
    "        return float(nutr.get(\"GCAL\"))\n",
    "    except (TypeError, ValueError, AttributeError):\n",
    "        return None\n",
    "\n",
    "def _is_water_like(name: str) -> bool:\n",
    "    n = norm(name)\n",
    "    return any(tok in n for tok in WATER_TOKENS)\n",
    "\n",
    "def has_nutrition(res: Dict[str, Any]) -> bool:\n",
    "    \"\"\"Valid if GCAL exists and > 0; for water-like items, accept GCAL==0/missing as valid.\"\"\"\n",
    "    name, _ = parse_detail(res)\n",
    "    if _is_water_like(name):\n",
    "        return True\n",
    "    gcal = _extract_gcal(res)\n",
    "    return (gcal is not None) and (gcal > 0.0)\n",
    "\n",
    "\n",
    "def try_prompt(amount, unit, ingredient, debug: bool = False):\n",
    "    prompt = f\"{amount} {unit} {ingredient}\".strip()\n",
    "    if debug:\n",
    "        print(f\"[API CALL] {prompt}\")\n",
    "    res = call_api(prompt)\n",
    "\n",
    "    if res is None:\n",
    "        if debug: print(\"  -> status: network_error\")\n",
    "        return None, prompt, \"network_error\"\n",
    "\n",
    "    if is_unrecognized(res):\n",
    "        if debug: print(\"  -> status: unrecognized\")\n",
    "        return res, prompt, \"unrecognized\"\n",
    "\n",
    "    name, _ = parse_detail(res)\n",
    "    if not ingredient_matches(str(ingredient), name):\n",
    "        if debug: print(f\"  -> status: mismatch (recognized as {name!r})\")\n",
    "        return res, prompt, \"mismatch\"\n",
    "\n",
    "    if not has_nutrition(res):\n",
    "        if debug: print(f\"  -> status: no_nutrition (recognized as {name!r})\")\n",
    "        return res, prompt, \"no_nutrition\"\n",
    "\n",
    "    if debug: print(f\"  -> status: ok (recognized as {name!r})\")\n",
    "    return res, prompt, \"ok\"\n",
    "\n",
    "\n",
    "# core logic that also returns status + used prompt\n",
    "def calc_nut_with_status(row, debug: bool = False):\n",
    "    \"\"\"\n",
    "    Returns: (nutrition_json_or_None, final_status, prompt_used, recognized_name_or_None)\n",
    "    \"\"\"\n",
    "    amount = row.get(\"norm_value\")\n",
    "    unit   = (row.get(\"norm_unit\") or \"\").strip().lower()  # \"g\" | \"liter\" | \"stück\"\n",
    "\n",
    "    # prefer 'zutat' from amount_annotation; fallback to 'ingredient'\n",
    "    zutat = None\n",
    "    aa = row.get(\"amount_annotation\")\n",
    "    if isinstance(aa, str) and aa.strip():\n",
    "        try:\n",
    "            zutat = json.loads(aa).get(\"zutat\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    ing_from_ann = zutat or row.get(\"ingredient\")\n",
    "    ing_plain    = row.get(\"ingredient\")\n",
    "\n",
    "    # 1) first attempt (annotation name or ingredient)\n",
    "    res1, p1, s1 = try_prompt(amount, unit, ing_from_ann, debug=debug)\n",
    "    if s1 == \"ok\":\n",
    "        name1, _ = parse_detail(res1)\n",
    "        return json.dumps(res1, ensure_ascii=False), s1, p1, name1\n",
    "\n",
    "    last_status, last_prompt, last_res = s1, p1, res1\n",
    "\n",
    "    # 2) only if first was \"no_nutrition\": try plain ingredient\n",
    "    if s1 == \"no_nutrition\" and ing_plain and norm(ing_plain) != norm(ing_from_ann):\n",
    "        res2, p2, s2 = try_prompt(amount, unit, ing_plain, debug=debug)\n",
    "        if s2 == \"ok\":\n",
    "            name2, _ = parse_detail(res2)\n",
    "            return json.dumps(res2, ensure_ascii=False), s2, p2, name2\n",
    "        last_status, last_prompt, last_res = s2, p2, res2\n",
    "\n",
    "    # 3) Stück/Liter → g fallback (only for content failures, not network)\n",
    "    if unit in {\"stück\", \"liter\"} and last_status in {\"no_nutrition\", \"mismatch\", \"unrecognized\"}:\n",
    "        res3, p3, s3 = try_prompt(amount, \"g\", ing_plain or ing_from_ann, debug=debug)\n",
    "        if s3 == \"ok\":\n",
    "            name3, _ = parse_detail(res3)\n",
    "            return json.dumps(res3, ensure_ascii=False), s3, p3, name3\n",
    "        # update trackers so failure report is accurate\n",
    "        last_status, last_prompt, last_res = s3, p3, res3\n",
    "\n",
    "    # failed: try to extract a recognized name if any\n",
    "    name = None\n",
    "    if isinstance(last_res, dict):\n",
    "        n, _ = parse_detail(last_res)\n",
    "        name = n or None\n",
    "    return None, last_status, last_prompt, name\n",
    "\n",
    "\n",
    "# i love tqdm ;)\n",
    "try:\n",
    "    HERE = Path(__file__).resolve()\n",
    "except NameError:\n",
    "    HERE = Path.cwd()\n",
    "\n",
    "data = pd.read_csv(HERE.parent / \"gemma_annotation_normalized.csv\", dtype=str)\n",
    "\n",
    "tqdm.pandas(desc=\"Fetching nutrition\")\n",
    "meta = data.progress_apply(calc_nut_with_status, axis=1, result_type=\"expand\")\n",
    "meta.columns = [\"nutrition\", \"status\", \"prompt_used\", \"recognized_name\"]\n",
    "\n",
    "out = pd.concat([data.reset_index(drop=True), meta], axis=1)\n",
    "\n",
    "found  = out[out[\"status\"] == \"ok\"].copy()\n",
    "failed = out[out[\"status\"] != \"ok\"].copy()\n",
    "\n",
    "found.to_csv(\"nutrition_found.csv\", index=False, encoding=\"utf-8\")\n",
    "failed.to_csv(\"nutrition_failed.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Done. Found: {len(found)} → nutrition_found.csv | Failed: {len(failed)} → nutrition_failed.csv\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching nutrition: 100%|██████████| 910/910 [04:13<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Found: 807 → nutrition_found.csv | Failed: 103 → nutrition_failed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6319519cc9b00d16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
